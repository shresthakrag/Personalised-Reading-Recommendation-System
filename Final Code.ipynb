{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55211fc2-a68a-47a0-8688-ee7b7d450eaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8c7fde5-e25f-4429-85dc-bcb257e5aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "#for deep learning model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d320db1-edc7-499b-9d76-3e33fa7da043",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72cb68be-aad8-4a6f-ad82-65c3ed84228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57f1e8aa-675c-4dc0-b315-761bbfaa9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('books.csv')\n",
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0d7b7da-9a0e-4d6d-83f4-c3f82d654573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m/2767052.jpg</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s/2767052.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m/3.jpg</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s/3.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1            2767052       2767052  2792775          272  439023483   \n",
       "1        2                  3             3  4640799          491  439554934   \n",
       "\n",
       "         isbn13                      authors  original_publication_year  \\\n",
       "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
       "1  9.780440e+12  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "\n",
       "                                                    image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m/2767052.jpg   \n",
       "1        https://images.gr-assets.com/books/1474154022m/3.jpg   \n",
       "\n",
       "                                              small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s/2767052.jpg  \n",
       "1        https://images.gr-assets.com/books/1474154022s/3.jpg  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d923aa6-5933-4ea6-aa62-bfc04acbd537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92f31a5b-5429-4d34-aa60-6635310b8501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_id', 'goodreads_book_id', 'best_book_id', 'work_id',\n",
       "       'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year',\n",
       "       'original_title', 'title', 'language_code', 'average_rating',\n",
       "       'ratings_count', 'work_ratings_count', 'work_text_reviews_count',\n",
       "       'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5',\n",
       "       'image_url', 'small_image_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bed35f-d403-4feb-b8ef-59e273bcaf25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Collaborative Filtering using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d538156-5960-4e68-afdf-d67bd46ae608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reader object for the Surprise library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load ratings into a Surprise dataset\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'book_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa60412-2881-43f2-8732-ee452aaf45ac",
   "metadata": {},
   "source": [
    "# Train-test split\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Implement SVD\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "import pickle\n",
    "# Save the trained model\n",
    "with open('svd_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svd, f)\n",
    "\n",
    "print(\"Model saved as 'svd_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74334f93-eb1d-440d-972a-318206c5fd6f",
   "metadata": {},
   "source": [
    "### Book Recommendations based on a User"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2eb28-3840-426a-9b41-50c4ca9a772c",
   "metadata": {},
   "source": [
    "**Load the saved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b73d96b5-06c8-46fb-a362-7f0ed3a12750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 'svd_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('svd_model.pkl', 'rb') as f:\n",
    "    loaded_svd = pickle.load(f)\n",
    "\n",
    "print(\"Model loaded from 'svd_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd7e14a9-f6b9-4661-a8d9-85ddb09cbe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend books for a user\n",
    "def recommend_books_for_user(user_id, books, model, n_recommendations=5):\n",
    "    all_book_ids = books['book_id'].unique()\n",
    "    rated_books = ratings[ratings['user_id'] == user_id]['book_id'].tolist()\n",
    "\n",
    "    book_predictions = []\n",
    "    for book_id in all_book_ids:\n",
    "        if book_id not in rated_books:\n",
    "            est_rating = model.predict(user_id, book_id).est\n",
    "            book_predictions.append((book_id, est_rating))\n",
    "\n",
    "    book_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_recommendations = book_predictions[:n_recommendations]\n",
    "\n",
    "    recommended_titles = []\n",
    "    for book_id, _ in top_recommendations:\n",
    "        title = books[books['book_id'] == book_id]['title'].values[0]\n",
    "        recommended_titles.append(title)\n",
    "\n",
    "    return recommended_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71b12fd1-7775-489f-9a06-552fb9d5e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user id:  8\n",
      "Enter the num of recommendation you want?  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended Books for User 8:\n",
      "1. Lamb: The Gospel According to Biff, Christ's Childhood Pal\n",
      "2. Saga, Vol. 3 (Saga, #3)\n",
      "3. The Complete Calvin and Hobbes\n",
      "4. Ficciones\n",
      "5. ESV Study Bible\n"
     ]
    }
   ],
   "source": [
    "user_id = int(input(\"Enter user id: \"))\n",
    "n_recommendations = int(input(\"Enter the num of recommendation you want? \"))\n",
    "recommended_titles = recommend_books_for_user(user_id, books, loaded_svd, n_recommendations)\n",
    "\n",
    "print(f\"Top recommended Books for User {user_id}:\")\n",
    "for i, title in enumerate(recommended_titles, 1):\n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b44f19-750a-4bd3-af0d-dd067aa17b9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Content Based Filtering using tf-idf & Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c71f9a1-bdfd-4149-9277-fe38ee991186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and authors for content-based filtering\n",
    "books['combined_text'] = books['title'] + ' ' + books['authors']\n",
    "\n",
    "# Feature extraction for content-based filtering\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "books['combined_text'] = books['combined_text'].fillna('')  # Fill NaN with empty strings\n",
    "tfidf_matrix = tfidf.fit_transform(books['combined_text'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28447d-8caf-4646-92b5-4aaced3678a2",
   "metadata": {},
   "source": [
    "### Recommendations based on Book Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3edcce31-3eb1-4ba2-8f8e-f58784b25a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the book that matches the title\n",
    "    if title not in books['title'].values:\n",
    "        return \"Title not found in the dataset.\"\n",
    "        \n",
    "    idx = books.index[books['title'] == title].tolist()[0]\n",
    "\n",
    "    # Get the pairwise similarity scores of all books with that book\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the books based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 5 most similar books\n",
    "    sim_scores = sim_scores[1:6]\n",
    "\n",
    "    # Get the book indices\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 5 most similar books\n",
    "    return books.iloc[book_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9815358-d57d-4666-b823-d139c8023241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     The Hunger Games (The Hunger Games, #1)\n",
       "1    Harry Potter and the Sorcerer's Stone (Harry Potter, #1)\n",
       "2                                     Twilight (Twilight, #1)\n",
       "3                                       To Kill a Mockingbird\n",
       "4                                            The Great Gatsby\n",
       "5                                      The Fault in Our Stars\n",
       "6                                                  The Hobbit\n",
       "7                                      The Catcher in the Rye\n",
       "8                       Angels & Demons  (Robert Langdon, #1)\n",
       "9                                         Pride and Prejudice\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bd31eea4-12e3-495b-b208-2430a6d1516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter book title:  The Great Gatsby\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>This Side of Paradise</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Tender Is the Night</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>The Beautiful and Damned</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8869</th>\n",
       "      <td>The Great Brain (Great Brain #1)</td>\n",
       "      <td>John D. Fitzgerald, Mercer Mayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>The Short Stories</td>\n",
       "      <td>F. Scott Fitzgerald, Matthew J. Bruccoli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "2303             This Side of Paradise   \n",
       "1183               Tender Is the Night   \n",
       "3254          The Beautiful and Damned   \n",
       "8869  The Great Brain (Great Brain #1)   \n",
       "7408                 The Short Stories   \n",
       "\n",
       "                                       authors  \n",
       "2303                       F. Scott Fitzgerald  \n",
       "1183                       F. Scott Fitzgerald  \n",
       "3254                       F. Scott Fitzgerald  \n",
       "8869          John D. Fitzgerald, Mercer Mayer  \n",
       "7408  F. Scott Fitzgerald, Matthew J. Bruccoli  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_input = input(\"Enter book title: \")\n",
    "recommended_books = get_recommendations(usr_input)\n",
    "print(\"Top 5 recommendations are:\")\n",
    "recommended_books[['title', 'authors']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbe484-aa08-4cd0-b04f-cde5e0556800",
   "metadata": {},
   "source": [
    "### Book Recommendations based on a User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3ea16bf-27e4-49f1-bfc6-a3d1758113a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommendations(user_id, n_recommendations, ratings, books, cosine_sim):\n",
    "    \n",
    "    # Get books the user has interacted with\n",
    "    user_books = ratings[ratings['user_id'] == user_id]\n",
    "\n",
    "    if user_books.empty:\n",
    "        return \"No interaction data found for this user.\"\n",
    "\n",
    "    # Aggregate the user's profile (weighted by ratings)\n",
    "    user_profile = np.zeros(cosine_sim.shape[0])\n",
    "    for _, row in user_books.iterrows():\n",
    "        book_idx = books.index[books['book_id'] == row['book_id']].tolist()[0]\n",
    "        user_profile += row['rating'] * cosine_sim[book_idx]\n",
    "    \n",
    "    # Normalize the user profile\n",
    "    user_profile = user_profile / np.linalg.norm(user_profile)\n",
    "\n",
    "    # Compute similarity scores with all books\n",
    "    sim_scores = list(enumerate(user_profile))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Filter out books the user has already interacted with\n",
    "    interacted_indices = set(user_books['book_id'].map(\n",
    "        lambda x: books.index[books['book_id'] == x].tolist()[0]))\n",
    "    sim_scores = [score for score in sim_scores if score[0] not in interacted_indices]\n",
    "\n",
    "    # Get the top n_recommendations recommended books\n",
    "    top_indices = [score[0] for score in sim_scores[:n_recommendations]]\n",
    "\n",
    "    # Return the recommended books\n",
    "    return books.iloc[top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a308652-1512-4806-8bae-e7af0abeda1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user id:  8\n",
      "Enter the num of recommendation you want?  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended Books for User 8:\n",
      "1. Lamb: The Gospel According to Biff, Christ's Childhood Pal\n",
      "2. Saga, Vol. 3 (Saga, #3)\n",
      "3. The Complete Calvin and Hobbes\n",
      "4. Ficciones\n",
      "5. ESV Study Bible\n"
     ]
    }
   ],
   "source": [
    "user_id = int(input(\"Enter user id: \"))\n",
    "n_recommendations = int(input(\"Enter the num of recommendation you want? \"))\n",
    "recommendations = get_user_recommendations(user_id, n_recommendations, ratings=ratings, books=books, cosine_sim=cosine_sim)\n",
    "\n",
    "print(f\"Top recommended Books for User {user_id}:\")\n",
    "for i, title in enumerate(recommended_titles, 1):\n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50068e0b-122f-4c7b-ad26-496b7d2f25a5",
   "metadata": {},
   "source": [
    "## Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "086bb78a-9ce7-4eb5-98c1-6c9bec65c14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user id:  2\n",
      "Enter the number of recommendations you want?  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended Books for User 2:\n",
      "1. The Harry Potter Collection 1-4 (Harry Potter, #1-4)\n",
      "2. Harry Potter Boxset (Harry Potter, #1-7)\n",
      "3. Harry Potter Boxed Set, Books 1-5 (Harry Potter, #1-5)\n",
      "4. Harry Potter and the Order of the Phoenix (Harry Potter, #5, Part 1)\n",
      "5. Harry Potter Page to Screen: The Complete Filmmaking Journey\n",
      "6. The Ultimate Hitchhiker's Guide to the Galaxy\n",
      "7. The Complete Works\n"
     ]
    }
   ],
   "source": [
    "# Function to get content-based recommendations as scores\n",
    "def get_content_based_scores(user_id, books, ratings, cosine_sim):\n",
    "    user_books = ratings[ratings['user_id'] == user_id]\n",
    "\n",
    "    if user_books.empty:\n",
    "        return np.zeros(cosine_sim.shape[0]), \"No interaction data found for this user.\"\n",
    "\n",
    "    # Aggregate the user's profile (weighted by ratings)\n",
    "    user_profile = np.zeros(cosine_sim.shape[0])\n",
    "    for _, row in user_books.iterrows():\n",
    "        book_idx = books.index[books['book_id'] == row['book_id']].tolist()[0]\n",
    "        user_profile += row['rating'] * cosine_sim[book_idx]\n",
    "\n",
    "    # Normalize the user profile\n",
    "    user_profile = user_profile / np.linalg.norm(user_profile)\n",
    "\n",
    "    return user_profile, None\n",
    "\n",
    "# Function to get collaborative filtering scores\n",
    "def get_collaborative_scores(user_id, books, model):\n",
    "    all_book_ids = books['book_id'].unique()\n",
    "    rated_books = ratings[ratings['user_id'] == user_id]['book_id'].tolist()\n",
    "\n",
    "    collaborative_scores = np.zeros(len(books))\n",
    "    for book_idx, book_id in enumerate(books['book_id']):\n",
    "        if book_id not in rated_books:\n",
    "            est_rating = model.predict(user_id, book_id).est\n",
    "            collaborative_scores[book_idx] = est_rating\n",
    "\n",
    "    return collaborative_scores\n",
    "\n",
    "# Weighted hybrid recommendation function\n",
    "def weighted_hybrid_recommendations(user_id, n_recommendations, books, ratings, cosine_sim, model, weight=0.5):\n",
    "    content_scores, content_error = get_content_based_scores(user_id, books, ratings, cosine_sim)\n",
    "    if content_error:\n",
    "        return content_error\n",
    "    \n",
    "    collaborative_scores = get_collaborative_scores(user_id, books, model)\n",
    "    \n",
    "    # Combine the scores using a weighted sum\n",
    "    hybrid_scores = weight * content_scores + (1 - weight) * collaborative_scores\n",
    "    \n",
    "    # Get top n_recommendations by sorting the scores\n",
    "    top_indices = np.argsort(hybrid_scores)[-n_recommendations:][::-1]\n",
    "    recommended_titles = books.iloc[top_indices]['title'].tolist()\n",
    "\n",
    "    return recommended_titles\n",
    "\n",
    "# Example usage\n",
    "user_id = int(input(\"Enter user id: \"))\n",
    "n_recommendations = int(input(\"Enter the number of recommendations you want? \"))\n",
    "recommended_titles = weighted_hybrid_recommendations(\n",
    "    user_id, n_recommendations, books, ratings, cosine_sim, loaded_svd, weight=0.5\n",
    ")\n",
    "\n",
    "print(f\"Top recommended Books for User {user_id}:\")\n",
    "for i, title in enumerate(recommended_titles, 1):\n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e54a5-a26a-4477-95a7-280bd0d36563",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f9d99-51ad-4f77-bf75-039018c74cdb",
   "metadata": {},
   "source": [
    "### Predicting Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f132b6f2-cc2c-4e9e-932f-76bedb9efb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input features and target\n",
    "X = np.random.rand(len(ratings), len(books.columns) + 1)  # Adjust this to include relevant features\n",
    "y = ratings['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1837670c-b800-4d09-b904-1762d4c95c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dprsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dropout(0.2)) #method for regularization of dl models\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer for regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72cc0daf-1016-41c5-811e-9b562dec2447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 2ms/step - loss: 1.0155 - val_loss: 0.9324\n",
      "Epoch 2/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2ms/step - loss: 0.9970 - val_loss: 0.9337\n",
      "Epoch 3/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 2ms/step - loss: 0.9946 - val_loss: 0.9321\n",
      "Epoch 4/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 2ms/step - loss: 0.9951 - val_loss: 0.9327\n",
      "Epoch 5/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 2ms/step - loss: 0.9966 - val_loss: 0.9321\n",
      "Epoch 6/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 2ms/step - loss: 0.9958 - val_loss: 0.9329\n",
      "Epoch 7/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2ms/step - loss: 0.9961 - val_loss: 0.9348\n",
      "Epoch 8/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 2ms/step - loss: 0.9942 - val_loss: 0.9327\n",
      "Epoch 9/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2ms/step - loss: 0.9967 - val_loss: 0.9321\n",
      "Epoch 10/10\n",
      "\u001b[1m149412/149412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2ms/step - loss: 0.9953 - val_loss: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29b51713ed0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcd9152e-eece-45ba-b8ae-409ddd9075c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict ratings using the deep learning model\n",
    "def predict_rating_dl(input_features):\n",
    "    return model.predict(np.array(input_features).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a4d1aa1-3a8c-4eff-b7c0-d92826f974e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Predicted Rating (DL): 3.892058849334717\n"
     ]
    }
   ],
   "source": [
    "predicted_rating_dl = predict_rating_dl(X[0])\n",
    "print(f'Predicted Rating (DL): {predicted_rating_dl[0][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6dac57-1faa-4b14-97ff-c98076c99a90",
   "metadata": {},
   "source": [
    "### Predicting Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b59a8cd-3e56-4700-b49a-8d880c95b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa764553-ab5d-4c4a-9d1f-e4be17fc696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings['user_id'].nunique()\n",
    "num_books = ratings['book_id'].nunique()\n",
    "\n",
    "# Prepare training and testing data\n",
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d580698c-0479-4e55-a542-eb774c21ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_model(num_users, num_books, embedding_size=50):\n",
    "    # User and Book Input Layers\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    book_input = Input(shape=(1,), name='book_input')\n",
    "\n",
    "    # User and Book Embeddings\n",
    "    user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, name='user_embedding')(user_input)\n",
    "    book_embedding = Embedding(input_dim=num_books, output_dim=embedding_size, name='book_embedding')(book_input)\n",
    "\n",
    "    # Flatten the embeddings\n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    book_vecs = Flatten()(book_embedding)\n",
    "\n",
    "    # Concatenate user and book embeddings\n",
    "    input_vecs = Concatenate()([user_vecs, book_vecs])\n",
    "\n",
    "    # Add Dense layers\n",
    "    x = Dense(128, activation='relu')(input_vecs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    y = Dense(1)(x)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[user_input, book_input], outputs=y)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model(num_users, num_books)\n",
    "\n",
    "# Define a checkpoint callback to save the model\n",
    "checkpoint = ModelCheckpoint('deep_model.keras', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c410c35e-a75c-4780-8396-d0b5ba7f65ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dprsh\\anaconda\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['user_input', 'book_input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1391s\u001b[0m 19ms/step - loss: 0.8576 - val_loss: 0.7279\n",
      "Epoch 2/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1653s\u001b[0m 22ms/step - loss: 0.7078 - val_loss: 0.6997\n",
      "Epoch 3/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1646s\u001b[0m 22ms/step - loss: 0.6607 - val_loss: 0.6891\n",
      "Epoch 4/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1414s\u001b[0m 19ms/step - loss: 0.6290 - val_loss: 0.6811\n",
      "Epoch 5/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1331s\u001b[0m 18ms/step - loss: 0.5984 - val_loss: 0.6797\n",
      "Epoch 6/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1324s\u001b[0m 18ms/step - loss: 0.5689 - val_loss: 0.6827\n",
      "Epoch 7/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1316s\u001b[0m 18ms/step - loss: 0.5397 - val_loss: 0.6903\n",
      "Epoch 8/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1324s\u001b[0m 18ms/step - loss: 0.5147 - val_loss: 0.6924\n",
      "Epoch 9/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1331s\u001b[0m 18ms/step - loss: 0.4913 - val_loss: 0.7142\n",
      "Epoch 10/10\n",
      "\u001b[1m74706/74706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1327s\u001b[0m 18ms/step - loss: 0.4686 - val_loss: 0.7149\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user id:  4\n",
      "Enter the number of recommendations you want?  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top recommended Books for User 4:\n",
      "1. Harry Potter Boxset (Harry Potter, #1-7) (Predicted Rating: 5.05)\n",
      "2. Harry Potter Boxed Set, Books 1-5 (Harry Potter, #1-5) (Predicted Rating: 5.02)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create mapping dictionaries for user_ids and book_ids\n",
    "user_mapping = {id_: i for i, id_ in enumerate(ratings['user_id'].unique())}\n",
    "book_mapping = {id_: i for i, id_ in enumerate(books['book_id'].unique())}\n",
    "\n",
    "# Create reverse mappings (for converting back to original IDs)\n",
    "reverse_user_mapping = {v: k for k, v in user_mapping.items()}\n",
    "reverse_book_mapping = {v: k for k, v in book_mapping.items()}\n",
    "\n",
    "# Map the IDs to sequential integers\n",
    "ratings['user_id_mapped'] = ratings['user_id'].map(user_mapping)\n",
    "ratings['book_id_mapped'] = ratings['book_id'].map(book_mapping)\n",
    "\n",
    "# Define the number of unique users and books\n",
    "num_users = len(user_mapping)\n",
    "num_books = len(book_mapping)\n",
    "\n",
    "# Prepare training and testing data\n",
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "def build_model(num_users, num_books, embedding_size=50):\n",
    "    # User and Book Input Layers\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    book_input = Input(shape=(1,), name='book_input')\n",
    "\n",
    "    # User and Book Embeddings\n",
    "    user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, name='user_embedding')(user_input)\n",
    "    book_embedding = Embedding(input_dim=num_books, output_dim=embedding_size, name='book_embedding')(book_input)\n",
    "\n",
    "    # Flatten the embeddings\n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    book_vecs = Flatten()(book_embedding)\n",
    "\n",
    "    # Concatenate user and book embeddings\n",
    "    input_vecs = Concatenate()([user_vecs, book_vecs])\n",
    "\n",
    "    # Add Dense layers\n",
    "    x = Dense(128, activation='relu')(input_vecs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    y = Dense(1)(x)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[user_input, book_input], outputs=y)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model(num_users, num_books)\n",
    "\n",
    "# Define a checkpoint callback to save the model\n",
    "checkpoint = ModelCheckpoint('deep_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Train the model using mapped IDs\n",
    "model.fit(\n",
    "    [train_ratings['user_id_mapped'].values, train_ratings['book_id_mapped'].values],\n",
    "    train_ratings['rating'].values,\n",
    "    validation_data=(\n",
    "        [test_ratings['user_id_mapped'].values, test_ratings['book_id_mapped'].values],\n",
    "        test_ratings['rating'].values\n",
    "    ),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f72cea88-9305-4eff-8487-b132d93e845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend books for a user\n",
    "def recommend_books_deep(user_id, books, model, n_recommendations=5):\n",
    "    # Map the user_id to the sequential ID\n",
    "    mapped_user_id = user_mapping.get(user_id)\n",
    "    if mapped_user_id is None:\n",
    "        return \"User ID not found in training data\"\n",
    "\n",
    "    all_book_ids = books['book_id'].unique()\n",
    "    rated_books = ratings[ratings['user_id'] == user_id]['book_id'].tolist()\n",
    "\n",
    "    book_predictions = []\n",
    "    for book_id in all_book_ids:\n",
    "        if book_id not in rated_books:\n",
    "            mapped_book_id = book_mapping.get(book_id)\n",
    "            if mapped_book_id is not None:\n",
    "                pred_rating = model.predict(\n",
    "                    [np.array([mapped_user_id]), np.array([mapped_book_id])],\n",
    "                    verbose=0\n",
    "                )[0][0]\n",
    "                book_predictions.append((book_id, pred_rating))\n",
    "\n",
    "    book_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_recommendations = book_predictions[:n_recommendations]\n",
    "\n",
    "    recommended_titles = []\n",
    "    for book_id, pred_rating in top_recommendations:\n",
    "        title = books[books['book_id'] == book_id]['title'].values[0]\n",
    "        recommended_titles.append((title, pred_rating))\n",
    "\n",
    "    return recommended_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bf4d0cb-d5de-4c38-ba12-7a46fd0e4d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user id:  2\n",
      "Enter the number of recommendations you want?  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_id = int(input(\"Enter user id: \"))\n",
    "n_recommendations = int(input(\"Enter the number of recommendations you want? \"))\n",
    "recommended_titles = recommend_books_deep(user_id, books, model, n_recommendations)\n",
    "\n",
    "print(f\"\\nTop recommended Books for User {user_id}:\")\n",
    "if isinstance(recommended_titles, str):\n",
    "    print(recommended_titles)\n",
    "else:\n",
    "    for i, (title, rating) in enumerate(recommended_titles, 1):\n",
    "        print(f\"{i}. {title} (Predicted Rating: {rating:.2f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8df7d089-e0ee-479a-a727-d91150227b8d",
   "metadata": {},
   "source": [
    "# Save the mappings for future use\n",
    "import pickle\n",
    "mapping_data = {\n",
    "    'user_mapping': user_mapping,\n",
    "    'book_mapping': book_mapping,\n",
    "    'reverse_user_mapping': reverse_user_mapping,\n",
    "    'reverse_book_mapping': reverse_book_mapping\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2667052-238d-4966-aacc-70fcf75f95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump(mapping_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a8168-e82e-4a61-8973-61571807bfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae01ea-0fea-4211-b69d-bfc85c623ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa15b9b-13b4-4d3c-b98c-6bdc457d5ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf8a39-c5b5-43fb-8c1d-38c49fd823bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
